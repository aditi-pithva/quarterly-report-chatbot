{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2cd24212-ff75-4258-b972-671e0b3f2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tabula-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c3f52cc-edd5-4d4e-8fb5-6b996b410bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tabula\n",
    "import numpy as np\n",
    "from tabula import read_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba208482-dac0-4ec4-b865-b8a21fcd3e89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Common Extracting and preprocessing Logic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a73bfc-b783-4290-b741-05594ff1ede7",
   "metadata": {},
   "source": [
    "## Extract tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e49132d9-4828-4a49-956c-dab3e647203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_from_pdf(pdf_path, page_number, area=None, multiple_tables=False, stream=True):\n",
    "    # Read tables from the specified PDF page and area\n",
    "    tables = read_pdf(\n",
    "        pdf_path,\n",
    "        pages=page_number,\n",
    "        area=area,  # Specify the area if provided\n",
    "        multiple_tables=multiple_tables,\n",
    "        stream=stream\n",
    "    )\n",
    "\n",
    "    # Initialize an empty DataFrame\n",
    "    table_df = pd.DataFrame()\n",
    "\n",
    "    if tables:\n",
    "        # Loop through the tables if multiple_tables is True\n",
    "        for i, table in enumerate(tables if isinstance(tables, list) else [tables]):\n",
    "            new_headers = table.iloc[0]\n",
    "            table.columns = new_headers\n",
    "            table = table.drop(0).reset_index(drop=True)\n",
    "            if not multiple_tables:\n",
    "                return table\n",
    "            else:\n",
    "                table_df = pd.concat([table_df, table], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"No tables found on page {page_number}.\")\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ed5d4-25d1-4583-90ec-41dd71d2674a",
   "metadata": {},
   "source": [
    "## Page 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e7b6091-018f-462e-b38d-57ad440cbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raname_page1_columns(table_df, column_renames=None, unnamed_column_start=1):\n",
    "    if table_df.empty:\n",
    "        raise ValueError(\"The input DataFrame is empty.\")\n",
    "\n",
    "    # Step 1: Replace NaN column names with sequential integers\n",
    "    table_df.columns = [\n",
    "        str(i) if pd.isna(col) else col\n",
    "        for i, col in enumerate(table_df.columns, start=unnamed_column_start)\n",
    "    ]\n",
    "\n",
    "    # Step 2: Rename columns based on the provided mapping\n",
    "    if column_renames:\n",
    "        table_df = table_df.rename(columns=column_renames)\n",
    "\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "872bce93-fd98-41e3-adbd-1f5dad96f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_and_unpivot_table_p1(table):\n",
    "    table.columns = table.columns.astype(str)\n",
    "\n",
    "    # Drop the first row if it's used as a header\n",
    "    table = table.iloc[1:].reset_index(drop=True)\n",
    "    \n",
    "    # Flatten any multi-dimensional data\n",
    "    table = table.applymap(lambda x: x if not isinstance(x, list) else ', '.join(map(str, x)))\n",
    "    \n",
    "    # Ensure the first column is the identifier\n",
    "    id_col = table.columns[0]\n",
    "\n",
    "    # Unpivot the table\n",
    "    try:\n",
    "        unpivoted_table = pd.melt(\n",
    "            table,\n",
    "            id_vars=[id_col],  # Use the first column as identifier\n",
    "            var_name=\"Column Name\",      # New column for original column names\n",
    "            value_name=\"Value\"           # New column for the cell values\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"Error while melting: {e}\")\n",
    "        print(f\"Columns: {table.columns}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame on failure\n",
    "\n",
    "    # Add a combined text column\n",
    "    unpivoted_table['text'] = unpivoted_table[id_col] + \" - \" + unpivoted_table[\"Column Name\"]\n",
    "    \n",
    "    # Clean the 'Value' column\n",
    "    unpivoted_table['Value'] = (\n",
    "        unpivoted_table['Value']\n",
    "        .astype(str)                          # Ensure values are strings for cleaning\n",
    "        .str.replace(r'[\\$%,]', '', regex=True)  # Remove $, %, and commas\n",
    "        .str.replace('million', '', regex=False) # Remove \"million\"\n",
    "        .str.strip()                          # Strip leading/trailing spaces\n",
    "    )\n",
    "    \n",
    "    # Replace 'nan' with np.NaN\n",
    "    unpivoted_table['Value'] = unpivoted_table['Value'].replace('nan', np.NaN)\n",
    "    \n",
    "    # Convert the 'Value' column to numeric\n",
    "    unpivoted_table['Value'] = pd.to_numeric(unpivoted_table['Value'], errors='coerce')\n",
    "    \n",
    "    # Drop unnecessary columns and keep 'text' and 'Value'\n",
    "    unpivoted_table = unpivoted_table[['text', 'Value']]\n",
    "    \n",
    "    return unpivoted_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34b24e-f92c-4476-b072-3193a758d3b2",
   "metadata": {},
   "source": [
    "## Page 3 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6873d94a-de6d-4a34-b0fb-870fb0c974a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_merged_columns(table, column_index, new_column_name=None):\n",
    "    # Extract data from the specified column\n",
    "    data_from_column = table.iloc[:, column_index]  # Get data from the specified column\n",
    "    header_of_column = table.columns[column_index]  # Get the header of the specified column\n",
    "\n",
    "    # Determine the new column name\n",
    "    if not new_column_name:\n",
    "        new_column_name = f\"New {header_of_column}\"\n",
    "\n",
    "    # Add the new column to the table\n",
    "    table[new_column_name] = data_from_column\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3c44b36-a2dc-4bfc-93d6-5132e857469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_columns(df, fourth_column_index=3, last_column_index=-1):\n",
    "    # Format the fourth column\n",
    "    fourth_column_name = df.columns[fourth_column_index]\n",
    "    df[fourth_column_name] = df[fourth_column_name].astype(str).apply(\n",
    "        lambda x: x.replace('$', '').replace(',', '').replace('\\xa0', ' ').strip() if isinstance(x, str) else x\n",
    "    )\n",
    "    df[fourth_column_name] = df[fourth_column_name].apply(\n",
    "        lambda x: x.split(' ')[0] if isinstance(x, str) and ' ' in x else x\n",
    "    )\n",
    "\n",
    "    # Format the last column\n",
    "    last_column_name = df.columns[last_column_index]\n",
    "    df[last_column_name] = df[last_column_name].astype(str).apply(\n",
    "        lambda x: x.replace('$', '').replace(',', '').replace('\\xa0', ' ').strip() if isinstance(x, str) else x\n",
    "    )\n",
    "    df[last_column_name] = df[last_column_name].apply(\n",
    "        lambda x: x.split(' ')[-1] if isinstance(x, str) and ' ' in x else x\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15b60531-289c-4db2-8d9b-663c2a72e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table_headers_and_convert(table_df, num_header_rows=4, handle_merged_columns=False):\n",
    "    # Save the existing column names (current header), converting NaNs to empty strings\n",
    "    original_headers = table_df.columns.astype(str).fillna('')\n",
    "    \n",
    "    # Extract the header rows\n",
    "    headers = table_df.iloc[:num_header_rows]\n",
    "    \n",
    "    # Fill NaN values in the header rows with an empty string\n",
    "    headers = headers.fillna('')\n",
    "    \n",
    "    # Merge the headers across the specified rows\n",
    "    combined_headers = headers.apply(lambda x: ' '.join(x.astype(str)).strip(), axis=0)\n",
    "    \n",
    "    # Include original header only if it's not 'nan'\n",
    "    combined_headers = [\n",
    "        f\"{original} {combined}\".strip() if original != 'nan' else combined\n",
    "        for original, combined in zip(original_headers, combined_headers)\n",
    "    ]\n",
    "    \n",
    "    # Remove columns where the merged header contains only \"Unnamed\" or is an empty string\n",
    "    filtered_columns = [\n",
    "        col for col in combined_headers if col.strip() and not col.strip().startswith('Unnamed')\n",
    "    ]\n",
    "    \n",
    "    # Filter the DataFrame to include only the non-\"Unnamed\" columns\n",
    "    table_df = table_df.loc[:, [col in filtered_columns for col in combined_headers]]\n",
    "    \n",
    "    # Assign the merged headers as the new column names\n",
    "    table_df.columns = [\n",
    "        col for col in combined_headers if col in filtered_columns\n",
    "    ]\n",
    "    \n",
    "    # Drop the original header rows now that they have been combined\n",
    "    table_df = table_df.drop(range(num_header_rows)).reset_index(drop=True)\n",
    "\n",
    "    # Handle specific column renaming (if required)\n",
    "    if handle_merged_columns:\n",
    "        table_df.rename(\n",
    "            columns={\n",
    "                'U.S. Capital Commercial Markets Banking and Direct and Wealth Financial Management Services': \n",
    "                'U.S. Commercial Banking and Wealth Management',\n",
    "                'New U.S. Capital Commercial Markets Banking and Direct and Wealth Financial Management Services': \n",
    "                'Capital Markets and Direct Financial Services'\n",
    "            },\n",
    "            inplace=True\n",
    "        )\n",
    "        # Format the fourth column\n",
    "        table_df = format_columns(table_df)\n",
    "    \n",
    "    # Clean the data: remove unwanted characters from numeric columns\n",
    "    for col in table_df.columns[1:]:  # Skip the first column (usually row labels)\n",
    "        table_df[col] = table_df[col].astype(str).str.replace(',', '', regex=False)\n",
    "        table_df[col] = table_df[col].str.replace('(', '-', regex=False)\n",
    "        table_df[col] = table_df[col].str.replace(')', '', regex=False)\n",
    "        table_df[col] = table_df[col].str.replace('$', '', regex=False)\n",
    "    \n",
    "    # Convert cleaned numeric columns to float\n",
    "    for col in table_df.columns[1:]:  # Skip the first column (usually text labels)\n",
    "        table_df[col] = pd.to_numeric(table_df[col], errors='coerce')\n",
    "    \n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6797dfbc-d47f-4ab9-8d3d-7e37d932d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_table_with_descriptive_text(table_df):\n",
    "    if table_df.empty:\n",
    "        raise ValueError(\"The input DataFrame is empty.\")\n",
    "    \n",
    "    # Melt the DataFrame\n",
    "    melted_df = pd.melt(\n",
    "        table_df, \n",
    "        id_vars=[table_df.columns[0]],  # Use the first column as the row label\n",
    "        var_name='header', \n",
    "        value_name='value'\n",
    "    )\n",
    "    \n",
    "    # Create descriptive 'text' by combining header and row label\n",
    "    melted_df['text'] = melted_df['header'] + \" - \" + melted_df[table_df.columns[0]]\n",
    "    \n",
    "    # Keep only the 'text' and 'value' columns\n",
    "    melted_df = melted_df[['text', 'value']]\n",
    "    \n",
    "    return melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9522c39-fb6c-44e4-b4e1-7c43d25b50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_matching_rows(df, phrases, primary_phrase, third_row_value_index=2):\n",
    "    # Filter rows where the 'text' column matches any of the specified phrases\n",
    "    matching_rows = df[df['text'].isin(phrases)].copy()  # Use .copy() to avoid the warning\n",
    "\n",
    "    # Remove 'primary_phrase' from all rows except the first\n",
    "    matching_rows.loc[:, 'text'] = matching_rows['text'].apply(\n",
    "        lambda x: x.replace(f\"{primary_phrase} - \", \"\") if x != phrases[0] else x\n",
    "    )\n",
    "\n",
    "    # Combine the 'text' values into a single string\n",
    "    combined_text = ' '.join(matching_rows['text'].unique())  # Concatenate unique text entries\n",
    "\n",
    "    # Check if there are any non-NaN values in the 'value' column, otherwise set to NaN\n",
    "    if matching_rows['value'].notna().any():\n",
    "        # Take the value from the specified row index\n",
    "        combined_value = matching_rows['value'].iloc[third_row_value_index]\n",
    "    else:\n",
    "        combined_value = np.nan  # Set to NaN if all are NaN\n",
    "\n",
    "    # Create a new DataFrame with the combined row\n",
    "    combined_row = pd.DataFrame({'text': [combined_text], 'value': [combined_value]})\n",
    "\n",
    "    # Drop the original matching rows and append the combined row\n",
    "    updated_df = df[~df['text'].isin(phrases)]\n",
    "    updated_df = pd.concat([updated_df, combined_row], ignore_index=True)\n",
    "\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c892243c-1e75-4c5a-8082-f06df8cb1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining conastant list for different phrases\n",
    "canadian_personal_phrases = [\n",
    "    \"Canadian Personal and Business Banking - Recovery to income tax that will be eliminated with the substantive\",\n",
    "    \"Canadian Personal and Business Banking - enactment of a Federal proposal to deny the dividends received\",\n",
    "    \"Canadian Personal and Business Banking - deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "capital_markets_phrases = [\n",
    "    \"Capital Markets and Direct Financial Services - Recovery to income tax that will be eliminated with the substantive\",\n",
    "    \"Capital Markets and Direct Financial Services - enactment of a Federal proposal to deny the dividends received\",\n",
    "    \"Capital Markets and Direct Financial Services - deduction for banks (2)\",\n",
    "]\n",
    "\n",
    "canadian_commercial_phrases = [\n",
    "    \"Canadian Commercial Banking and Wealth Management - Recovery to income tax that will be eliminated with the substantive\",\n",
    "    \"Canadian Commercial Banking and Wealth Management - enactment of a Federal proposal to deny the dividends received\",\n",
    "    \"Canadian Commercial Banking and Wealth Management - deduction for banks (2)\",\n",
    "]\n",
    "\n",
    "us_commercial_phrases = [\n",
    "    \"U.S. Commercial Banking and Wealth Management - Recovery to income tax that will be eliminated with the substantive\",\n",
    "    \"U.S. Commercial Banking and Wealth Management - enactment of a Federal proposal to deny the dividends received\",\n",
    "    \"U.S. Commercial Banking and Wealth Management - deduction for banks (2)\",\n",
    "]\n",
    "\n",
    "corporate_other_phrases = [\n",
    "    \"Corporate and Other - Recovery to income tax that will be eliminated with the substantive\",\n",
    "    \"Corporate and Other - enactment of a Federal proposal to deny the dividends received\",\n",
    "    \"Corporate and Other - deduction for banks (2)\",\n",
    "]\n",
    "\n",
    "cibc_total_phrases = [\n",
    "    \"CIBC Total - Recovery to income tax that will be eliminated with the substantive\",\n",
    "    \"CIBC Total - enactment of a Federal proposal to deny the dividends received\",\n",
    "    \"CIBC Total - deduction for banks (2)\",\n",
    "]\n",
    "\n",
    "commercial_banking_phrases = [\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - Recovery to income tax that will be eliminated with the substantive\",\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - enactment of a Federal proposal to deny the dividends received\",\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - deduction for banks (2)\",\n",
    "]\n",
    "\n",
    "phrases_list = [canadian_personal_phrases, capital_markets_phrases, canadian_commercial_phrases, us_commercial_phrases, corporate_other_phrases, cibc_total_phrases, commercial_banking_phrases]\n",
    "primary_phrase_list = [\"Canadian Personal and Business Banking\", \"Capital Markets and Direct Financial Services\", \"Canadian Commercial Banking and Wealth Management\",\n",
    "                      \"U.S. Commercial Banking and Wealth Management\", \"Corporate and Other\", \"CIBC Total\", \"Commercial Banking and Wealth Management (US$ millions)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "379f7bf7-368f-4331-923b-7c2e5ea689c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining conastant list for different phrases\n",
    "canadian_personal_phrases = [ \"Canadian Personal and Business Banking - Commodity tax charge related to the retroactive impact of the 2023\",\n",
    "    \"Canadian Personal and Business Banking - Canadian Federal budget\"\n",
    "]\n",
    "\n",
    "capital_markets_phrases = [ \"Capital Markets and Direct Financial Services - Commodity tax charge related to the retroactive impact of the 2023\",\n",
    "    \"Capital Markets and Direct Financial Services - Canadian Federal budget\"\n",
    "]\n",
    "\n",
    "canadian_commercial_phrases = [ \"Canadian Commercial Banking and Wealth Management - Commodity tax charge related to the retroactive impact of the 2023\",\n",
    "    \"Canadian Commercial Banking and Wealth Management - Canadian Federal budget\"\n",
    "]\n",
    "\n",
    "us_commercial_phrases = [ \"U.S. Commercial Banking and Wealth Management - Commodity tax charge related to the retroactive impact of the 2023\",\n",
    "    \"U.S. Commercial Banking and Wealth Management - Canadian Federal budget\"\n",
    "]\n",
    "\n",
    "corporate_other_phrases = [ \"Corporate and Other - Commodity tax charge related to the retroactive impact of the 2023\",\n",
    "    \"Corporate and Other - Canadian Federal budget\"\n",
    "]\n",
    "\n",
    "cibc_total_phrases = [ \"CIBC Total - Commodity tax charge related to the retroactive impact of the 2023\",\n",
    "    \"CIBC Total - Canadian Federal budget\"\n",
    "]\n",
    "\n",
    "commercial_banking_phrases = [ \"Commercial Banking and Wealth Management (US$ millions) - Commodity tax charge related to the retroactive impact of the 2023\",\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - Canadian Federal budget\"\n",
    "]\n",
    "\n",
    "q3_phrases_list = [canadian_personal_phrases, capital_markets_phrases, canadian_commercial_phrases, us_commercial_phrases, corporate_other_phrases, cibc_total_phrases, commercial_banking_phrases]\n",
    "q3_primary_phrase_list = [\"Canadian Personal and Business Banking\", \"Capital Markets and Direct Financial Services\", \"Canadian Commercial Banking and Wealth Management\",\n",
    "                      \"U.S. Commercial Banking and Wealth Management\", \"Corporate and Other\", \"CIBC Total\", \"Commercial Banking and Wealth Management (US$ millions)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e90fa-d9df-4b3d-991b-dbefeb457f34",
   "metadata": {},
   "source": [
    "## Last Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b64d0cbe-8665-4a13-b1c2-c8ab9d3e2e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table_headers_and_dates_for_last_page(table_df, num_header_rows=4):\n",
    "    # Step 1: Merge multi-row headers\n",
    "    original_headers = table_df.columns.astype(str).fillna('')\n",
    "    headers = table_df.iloc[:num_header_rows].fillna('')\n",
    "    combined_headers = headers.apply(lambda x: ' '.join(x.astype(str)).strip(), axis=0)\n",
    "    combined_headers = [\n",
    "        f\"{original} {combined}\".strip() if original != 'nan' else combined\n",
    "        for original, combined in zip(original_headers, combined_headers)\n",
    "    ]\n",
    "    table_df.columns = combined_headers\n",
    "    table_df = table_df.drop(range(num_header_rows)).reset_index(drop=True)\n",
    "\n",
    "    # Remove columns with empty or \"Unnamed\" headers\n",
    "    filtered_columns = [\n",
    "        col for col in table_df.columns if col.strip() and not col.strip().startswith('Unnamed')\n",
    "    ]\n",
    "    table_df = table_df.loc[:, filtered_columns]\n",
    "    \n",
    "    # Step 2: Extract year, month, and day from the first column\n",
    "    table_df['Year'] = table_df.iloc[:, 0].str.extract(r'(\\d{4})')  # Extract the year\n",
    "    table_df['Year'] = table_df['Year'].fillna(method='ffill')  # Propagate year downward\n",
    "    table_df['Month_Day'] = table_df.iloc[:, 0].str.extract(r'([A-Za-z]+\\.? \\d{1,2})')  # Extract month/day\n",
    "    table_df['Date'] = (table_df['Year'] + ' ' + table_df['Month_Day']).str.strip()  # Combine into \"Date\"\n",
    "    \n",
    "    # Step 3: Clean the first column (remove extracted year and month/day)\n",
    "    table_df.iloc[:, 0] = table_df.iloc[:, 0].str.replace(r'(\\d{4})', '', regex=True)  # Remove year\n",
    "    table_df.iloc[:, 0] = table_df.iloc[:, 0].str.replace(r'([A-Za-z]+\\.? \\d{1,2})', '', regex=True)  # Remove month/day\n",
    "    table_df.iloc[:, 0] = table_df.iloc[:, 0].str.strip()  # Remove extra spaces\n",
    "    \n",
    "    # Drop temporary columns used for date extraction\n",
    "    table_df.drop(columns=['Year', 'Month_Day'], inplace=True)\n",
    "\n",
    "    # Step 4: Clean numeric columns\n",
    "    for col in table_df.columns[1:]:  # Skip the first column (usually descriptive text)\n",
    "        if col != 'Date':  # Skip the \"Date\" column\n",
    "            table_df[col] = table_df[col].astype(str).str.replace(',', '', regex=False)\n",
    "            table_df[col] = table_df[col].str.replace('(', '-', regex=False)\n",
    "            table_df[col] = table_df[col].str.replace(')', '', regex=False)\n",
    "            table_df[col] = table_df[col].str.replace('$', '', regex=False)\n",
    "            table_df[col] = pd.to_numeric(table_df[col], errors='coerce')  # Convert to numeric\n",
    "\n",
    "    return table_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c6e4ef1-72d9-4137-b0f3-2faf5935596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_melt_table_with_date(table_df, date_column='Date', date_replacements=None):\n",
    "    if table_df.empty:\n",
    "        raise ValueError(\"The input DataFrame is empty.\")\n",
    "\n",
    "    # Ensure the Date column exists in the DataFrame\n",
    "    if date_column not in table_df.columns:\n",
    "        raise ValueError(f\"The specified date column '{date_column}' does not exist in the DataFrame.\")\n",
    "\n",
    "    # Step 1: Melt the DataFrame, excluding the Date column\n",
    "    melted_df = pd.melt(\n",
    "        table_df,\n",
    "        id_vars=[table_df.columns[0], date_column],  # Keep the first column and Date column as id_vars\n",
    "        var_name='header',\n",
    "        value_name='value'\n",
    "    )\n",
    "    \n",
    "    # Step 2: Create descriptive 'text' by combining header and row label\n",
    "    melted_df['text'] = melted_df['header'] + \" - \" + melted_df[table_df.columns[0]]\n",
    "\n",
    "    # Keep only the 'Date', 'text', and 'value' columns\n",
    "    melted_df = melted_df[['Date', 'text', 'value']]\n",
    "\n",
    "    # Step 3: Replace values in the 'Date' column if replacements are provided\n",
    "    if date_replacements:\n",
    "        melted_df['Date'] = melted_df['Date'].replace(date_replacements)\n",
    "\n",
    "    # Step 4: Fill missing 'Date' values using neighboring values\n",
    "    rows = len(melted_df)\n",
    "    for i in range(rows):\n",
    "        # If the first row is NaN, fill it with the next row's value\n",
    "        if i == 0 and pd.isna(melted_df.loc[i, date_column]):\n",
    "            melted_df.loc[i, date_column] = melted_df.loc[i + 1, date_column]\n",
    "        \n",
    "        # If a NaN is encountered\n",
    "        elif pd.isna(melted_df.loc[i, date_column]):\n",
    "            # If it's the last row, fill it with the previous value\n",
    "            if i == rows - 1:\n",
    "                melted_df.loc[i, date_column] = melted_df.loc[i - 1, date_column]\n",
    "            # If the next row is not NaN, fill the current NaN with the next row's value\n",
    "            elif not pd.isna(melted_df.loc[i + 1, date_column]):\n",
    "                melted_df.loc[i, date_column] = melted_df.loc[i + 1, date_column]\n",
    "            # Otherwise, fill the current NaN with the previous value\n",
    "            else:\n",
    "                melted_df.loc[i, date_column] = melted_df.loc[i - 1, date_column]\n",
    "\n",
    "    # Step 5: Merge 'Date' and 'text' columns with '-'\n",
    "    melted_df['text'] =  melted_df['text'] + \" - \" + melted_df['Date'] \n",
    "\n",
    "    melted_df.drop(columns = 'Date', inplace = True)\n",
    "\n",
    "    return melted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff5617-50dd-49e6-bc4b-b4ef01fb13ad",
   "metadata": {},
   "source": [
    "# 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac0a28-4ced-4405-a97c-bb37f0df0772",
   "metadata": {},
   "source": [
    "## Q3 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6abd70f8-44a8-4bd6-820c-1d204f451ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'q324newsrelease-en.pdf'\n",
    "\n",
    "q324_processed_table_page_1 = extract_table_from_pdf(pdf_path, 1, [155, 20, 290, 576])\n",
    "q324_processed_table_page_3 = extract_table_from_pdf(pdf_path, 3, [210, 20, 610, 800]) # Merged column #phrases_list_p3_p6\n",
    "q324_processed_table_page_4 = extract_table_from_pdf(pdf_path, 4) # primary_phrase_list\n",
    "q324_processed_table_page_5 = extract_table_from_pdf(pdf_path, 5) # q3_primary_phrase_list\n",
    "q324_processed_table_page_6 = extract_table_from_pdf(pdf_path, 6) # Merged column, phrases_list_p3_p6\n",
    "q324_processed_table_page_7 = extract_table_from_pdf(pdf_path, 7) # q3_primary_phrase_list\n",
    "q324_processed_table_page_8 = extract_table_from_pdf(pdf_path, 8, [70, 20, 420, 800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1bbfb-04f5-4b11-8c21-7c6effa9af9d",
   "metadata": {},
   "source": [
    "### Q3 2024 - Page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e175168e-4d8a-4cbf-835b-903ababc5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column renames\n",
    "column_renames = {\n",
    "    'Q3/24': 'Q3 2024',\n",
    "    'Q3/23 (1)': 'Q3 2023',\n",
    "    'Q2/24': 'Q2 2024',\n",
    "    '1': 'text',\n",
    "    '5': 'YoY Variance',\n",
    "    '6': 'QoQ Variance',\n",
    "}\n",
    "\n",
    "# Raname columns\n",
    "q324_processed_table_page_1 = raname_page1_columns(\n",
    "    table_df=q324_processed_table_page_1,\n",
    "    column_renames=column_renames,\n",
    "    unnamed_column_start=1\n",
    ")\n",
    "\n",
    "# Process the table\n",
    "q324_processed_df_page_1 = process_and_unpivot_table_p1(q324_processed_table_page_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039fbbc2-57fa-4853-adbd-9d0025e94d2f",
   "metadata": {},
   "source": [
    "### Q3 2024 - Page 3 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1532f180-ff9c-43d4-82c7-638680993dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining conastant list for different phrases\n",
    "canadian_personal_phrases = [ \"Canadian Personal and Business Banking - Adjustments related to enactment of a Federal tax measure in June\",\n",
    "    \"Canadian Personal and Business Banking - 2024 that denies the dividends received deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "capital_markets_phrases = [ \"Capital Markets and Direct Financial Services - Adjustments related to enactment of a Federal tax measure in June\",\n",
    "    \"Capital Markets and Direct Financial Services - 2024 that denies the dividends received deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "canadian_commercial_phrases = [ \"Canadian Commercial Banking and Wealth Management - Adjustments related to enactment of a Federal tax measure in June\",\n",
    "    \"Canadian Commercial Banking and Wealth Management - 2024 that denies the dividends received deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "us_commercial_phrases = [ \"U.S. Commercial Banking and Wealth Management - Adjustments related to enactment of a Federal tax measure in June\",\n",
    "    \"U.S. Commercial Banking and Wealth Management - 2024 that denies the dividends received deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "corporate_other_phrases = [ \"Corporate and Other - Adjustments related to enactment of a Federal tax measure in June\",\n",
    "    \"Corporate and Other - 2024 that denies the dividends received deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "cibc_total_phrases = [ \"CIBC Total - Adjustments related to enactment of a Federal tax measure in June\",\n",
    "    \"CIBC Total - 2024 that denies the dividends received deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "commercial_banking_phrases = [ \"Commercial Banking and Wealth Management (US$ millions) - Adjustments related to enactment of a Federal tax measure in June\",\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - 2024 that denies the dividends received deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "phrases_list_p3_p6 = [canadian_personal_phrases, capital_markets_phrases, canadian_commercial_phrases, us_commercial_phrases, \n",
    "                   corporate_other_phrases, cibc_total_phrases, commercial_banking_phrases]\n",
    "\n",
    "primary_phrase_list_p3_p6 = [\"Canadian Personal and Business Banking\", \"Capital Markets and Direct Financial Services\", \n",
    "                          \"Canadian Commercial Banking and Wealth Management\", \"U.S. Commercial Banking and Wealth Management\",\n",
    "                          \"Corporate and Other\", \"CIBC Total\", \"Commercial Banking and Wealth Management (US$ millions)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe8ab85f-e501-4cd7-9ab3-1b64f8be1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column to merged columns\n",
    "q324_processed_table_page_3 = split_merged_columns(q324_processed_table_page_3, column_index=3)\n",
    "q324_processed_table_page_6 = split_merged_columns(q324_processed_table_page_6, column_index=3)\n",
    "\n",
    "q324_processed_df_page_3 = process_table_headers_and_convert(q324_processed_table_page_3, num_header_rows=4, handle_merged_columns=True)\n",
    "q324_processed_df_page_4 = process_table_headers_and_convert(q324_processed_table_page_4, num_header_rows=4)\n",
    "q324_processed_df_page_5 = process_table_headers_and_convert(q324_processed_table_page_5, num_header_rows=4)\n",
    "q324_processed_df_page_6 = process_table_headers_and_convert(q324_processed_table_page_6, num_header_rows=4, handle_merged_columns=True)\n",
    "q324_processed_df_page_7 = process_table_headers_and_convert(q324_processed_table_page_7, num_header_rows=4)\n",
    "\n",
    "q324_processed_df_page_3 = melt_table_with_descriptive_text(q324_processed_df_page_3)\n",
    "q324_processed_df_page_4 = melt_table_with_descriptive_text(q324_processed_df_page_4)\n",
    "q324_processed_df_page_5 = melt_table_with_descriptive_text(q324_processed_df_page_5)\n",
    "q324_processed_df_page_6 = melt_table_with_descriptive_text(q324_processed_df_page_6)\n",
    "q324_processed_df_page_7 = melt_table_with_descriptive_text(q324_processed_df_page_7)\n",
    "\n",
    "for phrase, primary_phrase in zip(phrases_list, primary_phrase_list):\n",
    "    q324_processed_df_page_4 = merge_matching_rows(q324_processed_df_page_4, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "for phrase, primary_phrase in zip(phrases_list_p3_p6, primary_phrase_list_p3_p6):\n",
    "    q324_processed_df_page_3 = merge_matching_rows(q324_processed_df_page_3, phrase, primary_phrase=primary_phrase)\n",
    "    q324_processed_df_page_6= merge_matching_rows(q324_processed_df_page_6, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "for phrase, primary_phrase in zip(q3_phrases_list, q3_primary_phrase_list):\n",
    "    q324_processed_df_page_5 = merge_matching_rows(q324_processed_df_page_5, phrase, primary_phrase=primary_phrase)\n",
    "    q324_processed_df_page_7= merge_matching_rows(q324_processed_df_page_7, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "q324_processed_df_page_3['text'] = q324_processed_df_page_3['text'].astype(str) + 'Q3 2024 three months end'\n",
    "q324_processed_df_page_4['text'] = q324_processed_df_page_4['text'].astype(str) + 'Q2 2024 three months end'\n",
    "q324_processed_df_page_5['text'] = q324_processed_df_page_5['text'].astype(str) + 'Q3 2023 three months end'\n",
    "q324_processed_df_page_6['text'] = q324_processed_df_page_6['text'].astype(str) + 'Q3 2024 nine months end'\n",
    "q324_processed_df_page_7['text'] = q324_processed_df_page_7['text'].astype(str) + 'Q3 2023 nine months end'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65bbca4-301b-47a7-8bd8-d0693a573d6b",
   "metadata": {},
   "source": [
    "### Q3 2024 - Page 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b0cbcd3b-6c4b-4eff-8c63-3aa19d79ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "q324_processed_df_page_8 = process_table_headers_and_dates_for_last_page(q324_processed_table_page_8, num_header_rows=4)\n",
    "\n",
    "date_replacements = {\n",
    "    'nan': np.nan,        # Replace 'nan' with np.nan\n",
    "    '2024 Jul. 31': 'Q3 2024',\n",
    "    '2024 Apr. 30': 'Q2 2024',\n",
    "    '2023 Jul. 31': 'Q3 2023',\n",
    "}\n",
    "\n",
    "q324_processed_df_page_8 = process_and_melt_table_with_date(\n",
    "    table_df=q324_processed_df_page_8,\n",
    "    date_column='Date',\n",
    "    date_replacements=date_replacements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f1b1f7-6bcb-485e-8c20-efd1cadff2d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q2 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac613d6-f590-4946-b264-d63455b42353",
   "metadata": {},
   "source": [
    "### Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49de9e4e-8c58-4310-806c-52e685414fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'q224newsrelease-en.pdf'\n",
    "page_3_area = [300, 20, 610, 800]\n",
    "\n",
    "q224_processed_table_page_1 = extract_table_from_pdf(pdf_path, 1)\n",
    "q224_processed_table_page_3 = extract_table_from_pdf(pdf_path, 3, page_3_area)\n",
    "q224_processed_table_page_4 = extract_table_from_pdf(pdf_path, 4)\n",
    "q224_processed_table_page_5 = extract_table_from_pdf(pdf_path, 5)\n",
    "q224_processed_table_page_6 = extract_table_from_pdf(pdf_path, 6)\n",
    "q224_processed_table_page_7 = extract_table_from_pdf(pdf_path, 7)\n",
    "q224_processed_table_page_8 = extract_table_from_pdf(pdf_path, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39bdb0-4643-4b2b-a3b8-61cc3c9ce83f",
   "metadata": {},
   "source": [
    "### Q2 2024 - Page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "876299a4-e365-4617-94b9-9ab153eb9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column renames\n",
    "column_renames = {\n",
    "    'Q2/24': 'Q2 2024',\n",
    "    'Q2/23 (1)': 'Q2 2023',\n",
    "    'Q1/24': 'Q1 2024',\n",
    "    '1': 'text',\n",
    "    '5': 'YoY Variance',\n",
    "    '6': 'QoQ Variance',\n",
    "}\n",
    "\n",
    "# Raname columns\n",
    "q224_processed_table_page_1 = raname_page1_columns(\n",
    "    table_df=q224_processed_table_page_1,\n",
    "    column_renames=column_renames,\n",
    "    unnamed_column_start=1\n",
    ")\n",
    "\n",
    "# Process the table\n",
    "q224_processed_df_page_1 = process_and_unpivot_table_p1(q224_processed_table_page_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682ea35-e7a4-4156-b9ad-a1584fdc4942",
   "metadata": {},
   "source": [
    "### Q2 2024 - Page 3 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6106784c-47a1-40d1-8ad5-3bd8ff06e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column to merged columns\n",
    "q224_processed_table_page_3 = split_merged_columns(q224_processed_table_page_3, column_index=3)\n",
    "q224_processed_table_page_6 = split_merged_columns(q224_processed_table_page_6, column_index=3)\n",
    "\n",
    "q224_processed_df_page_3 = process_table_headers_and_convert(q224_processed_table_page_3, num_header_rows=4, handle_merged_columns=True)\n",
    "q224_processed_df_page_4 = process_table_headers_and_convert(q224_processed_table_page_4, num_header_rows=4)\n",
    "q224_processed_df_page_5 = process_table_headers_and_convert(q224_processed_table_page_5, num_header_rows=4)\n",
    "q224_processed_df_page_6 = process_table_headers_and_convert(q224_processed_table_page_6, num_header_rows=4, handle_merged_columns=True)\n",
    "q224_processed_df_page_7 = process_table_headers_and_convert(q224_processed_table_page_7, num_header_rows=4)\n",
    "\n",
    "q224_processed_df_page_3 = melt_table_with_descriptive_text(q224_processed_df_page_3)\n",
    "q224_processed_df_page_4 = melt_table_with_descriptive_text(q224_processed_df_page_4)\n",
    "q224_processed_df_page_5 = melt_table_with_descriptive_text(q224_processed_df_page_5)\n",
    "q224_processed_df_page_6 = melt_table_with_descriptive_text(q224_processed_df_page_6)\n",
    "q224_processed_df_page_7 = melt_table_with_descriptive_text(q224_processed_df_page_7)\n",
    "\n",
    "for phrase, primary_phrase in zip(phrases_list, primary_phrase_list):\n",
    "    q224_processed_df_page_3 = merge_matching_rows(q224_processed_df_page_3, phrase, primary_phrase=primary_phrase)\n",
    "    q224_processed_df_page_4 = merge_matching_rows(q224_processed_df_page_4, phrase, primary_phrase=primary_phrase)\n",
    "    q224_processed_df_page_6 = merge_matching_rows(q224_processed_df_page_6, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "\n",
    "q224_processed_df_page_3['text'] = q224_processed_df_page_3['text'].astype(str) + 'Q2 2024 three months end'\n",
    "q224_processed_df_page_4['text'] = q224_processed_df_page_4['text'].astype(str) + 'Q1 2024 three months end'\n",
    "q224_processed_df_page_5['text'] = q224_processed_df_page_5['text'].astype(str) + 'Q2 2023 three months end'\n",
    "q224_processed_df_page_6['text'] = q224_processed_df_page_6['text'].astype(str) + 'Q2 2024 six months end'\n",
    "q224_processed_df_page_7['text'] = q224_processed_df_page_7['text'].astype(str) + 'Q2 2023 six months end'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82501abb-e052-4e5f-818b-e7e6ac88056b",
   "metadata": {},
   "source": [
    "### Q2 2024 - Page 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a98cfcd1-78a7-4e4f-96b4-c22e5cdfe0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q224_processed_df_page_8 = process_table_headers_and_dates_for_last_page(q224_processed_table_page_8, num_header_rows=4)\n",
    "\n",
    "date_replacements = {\n",
    "    'nan': np.nan,        # Replace 'nan' with np.nan\n",
    "    '2024 Apr. 30': 'Q2 2024',\n",
    "    '2024 Jan. 31': 'Q1 2024',\n",
    "    '2023 Apr. 30': 'Q2 2023'\n",
    "}\n",
    "\n",
    "q224_processed_df_page_8 = process_and_melt_table_with_date(\n",
    "    table_df=q224_processed_df_page_8,\n",
    "    date_column='Date',\n",
    "    date_replacements=date_replacements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ccdb94-a1e5-4846-b358-4a33ddd9f6fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q1 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "581f2a9b-f28b-4acf-b597-fc666e2e5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'q124newsrelease-en.pdf' \n",
    "\n",
    "q124_processed_table_page_1 = extract_table_from_pdf(pdf_path, 1, [145, 30, 310, 576])\n",
    "q124_processed_table_page_3 = extract_table_from_pdf(pdf_path, 3, [210, 20, 610, 800])\n",
    "q124_processed_table_page_4 = extract_table_from_pdf(pdf_path, 4, [60, 30, 370, 600])\n",
    "q124_processed_table_page_4_2 = extract_table_from_pdf(pdf_path, 4, [400, 30, 740, 600])\n",
    "q124_processed_table_page_5 = extract_table_from_pdf(pdf_path, 5, [70, 30, 290, 600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e522d-e865-48d9-895e-5e1122988d54",
   "metadata": {},
   "source": [
    "### Q1 2024 - Page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0cfb668f-0582-4617-a95c-6ad97a82bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column renames\n",
    "column_renames = {\n",
    "    'Q1/24': 'Q1 2024',\n",
    "    'Q1/23 (1)\t': 'Q1 2023',\n",
    "    'Q4/23 (1)': 'Q4 2023',\n",
    "    '1': 'text',\n",
    "    '5': 'YoY Variance',\n",
    "    '6': 'QoQ Variance',\n",
    "}\n",
    "\n",
    "# Raname columns\n",
    "q124_processed_table_page_1 = raname_page1_columns(\n",
    "    table_df=q124_processed_table_page_1,\n",
    "    column_renames=column_renames,\n",
    "    unnamed_column_start=1\n",
    ")\n",
    "\n",
    "# Process the table\n",
    "q124_processed_df_page_1 = process_and_unpivot_table_p1(q124_processed_table_page_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0879cb8c-70b3-4116-bc98-54189b67adab",
   "metadata": {},
   "source": [
    "### Q1 2024 - Page 3 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd5d9155-da76-4e7c-af7f-d9a77edd9503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canadian Personal and Business Banking - Opera...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canadian Personal and Business Banking - Total...</td>\n",
       "      <td>2497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canadian Personal and Business Banking - Provi...</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian Personal and Business Banking - Non-i...</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canadian Personal and Business Banking - Incom...</td>\n",
       "      <td>888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Capital Markets and Direct Financial Services ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Capital Markets and Direct Financial Services ...</td>\n",
       "      <td>575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Capital Markets and Direct Financial Services ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Capital Markets and Direct Financial Services ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Capital Markets and Direct Financial Services ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text   value\n",
       "0    Canadian Personal and Business Banking - Opera...     NaN\n",
       "1    Canadian Personal and Business Banking - Total...  2497.0\n",
       "2    Canadian Personal and Business Banking - Provi...   329.0\n",
       "3    Canadian Personal and Business Banking - Non-i...  1280.0\n",
       "4    Canadian Personal and Business Banking - Incom...   888.0\n",
       "..                                                 ...     ...\n",
       "261  Capital Markets and Direct Financial Services ...     NaN\n",
       "262  Capital Markets and Direct Financial Services ...   575.0\n",
       "263  Capital Markets and Direct Financial Services ...     NaN\n",
       "264  Capital Markets and Direct Financial Services ...     NaN\n",
       "265  Capital Markets and Direct Financial Services ...     NaN\n",
       "\n",
       "[266 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q124_processed_df_page_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f59818f-d3cd-4010-8953-1d590a27582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column to merged columns\n",
    "q124_processed_table_page_3 = split_merged_columns(q124_processed_table_page_3, column_index=3)\n",
    "\n",
    "q124_processed_df_page_3 = process_table_headers_and_convert(q124_processed_table_page_3, num_header_rows=4, handle_merged_columns=True)\n",
    "q124_processed_df_page_4 = process_table_headers_and_convert(q124_processed_table_page_4, num_header_rows=4)\n",
    "q124_processed_df_page_4_2 = process_table_headers_and_convert(q124_processed_table_page_5, num_header_rows=4)\n",
    "\n",
    "q124_processed_df_page_3 = melt_table_with_descriptive_text(q124_processed_df_page_3)\n",
    "q124_processed_df_page_4 = melt_table_with_descriptive_text(q124_processed_df_page_4)\n",
    "q124_processed_df_page_4_2 = melt_table_with_descriptive_text(q124_processed_df_page_4_2)\n",
    "\n",
    "q124_processed_df_page_3['text'] = q124_processed_df_page_3['text'].astype(str) + 'Q1 2024 three months end'\n",
    "q124_processed_df_page_4['text'] = q124_processed_df_page_4['text'].astype(str) + 'Q4 2023 three months end'\n",
    "q124_processed_df_page_4_2['text'] = q124_processed_df_page_4_2['text'].astype(str) + 'Q1 2023 three months end'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6ce86-c26e-4388-992e-68e27b22e528",
   "metadata": {},
   "source": [
    "### Q1 2024 - Page 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3d0e786c-0de1-46fa-aeb1-3b9100177365",
   "metadata": {},
   "outputs": [],
   "source": [
    "q124_processed_df_page_5 = process_table_headers_and_dates_for_last_page(q124_processed_table_page_5, num_header_rows=4)\n",
    "\n",
    "date_replacements = {\n",
    "    'nan': np.nan,        # Replace 'nan' with np.nan\n",
    "    '2024 Jan. 31': 'Q1 2024',\n",
    "    '2023 Oct. 31': 'Q4 2023',\n",
    "    '2023 Jan. 31': 'Q1 2023'\n",
    "}\n",
    "\n",
    "q124_processed_df_page_5 = process_and_melt_table_with_date(\n",
    "    table_df=q124_processed_df_page_5,\n",
    "    date_column='Date',\n",
    "    date_replacements=date_replacements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387e25e-69eb-43a2-afc0-bf9c47e9e324",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910f975-47f9-42af-a6ea-2275212b2f0b",
   "metadata": {},
   "source": [
    "## Q3 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a690ae5-1a2e-4dfa-b624-da58673618e1",
   "metadata": {},
   "source": [
    "### Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c6b5c7b1-e47b-411c-b997-8eaf4eddb0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'q323newsrelease-en.pdf'\n",
    "\n",
    "q323_processed_table_page_1 = extract_table_from_pdf(pdf_path, 1, [155, 20, 290, 576])\n",
    "q323_processed_table_page_3 = extract_table_from_pdf(pdf_path, 3, [210, 20, 610, 800])\n",
    "q323_processed_table_page_4 = extract_table_from_pdf(pdf_path, 4)\n",
    "q323_processed_table_page_5 = extract_table_from_pdf(pdf_path, 5)\n",
    "q323_processed_table_page_6 = extract_table_from_pdf(pdf_path, 6)\n",
    "q323_processed_table_page_7 = extract_table_from_pdf(pdf_path, 7)\n",
    "q323_processed_table_page_8 = extract_table_from_pdf(pdf_path, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29396af1-0efa-4e11-9b5a-f6f0e23aabe1",
   "metadata": {},
   "source": [
    "### Q3 2023 - Page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c7563781-4db4-4ece-b48a-800fee861867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column renames\n",
    "column_renames = {\n",
    "    'Q3/23': 'Q3 2023',\n",
    "    'Q3/22': 'Q3 2022',\n",
    "    'Q2/23': 'Q2 2023',\n",
    "    '1': 'text',\n",
    "    '5': 'YoY Variance',\n",
    "    '6': 'QoQ Variance',\n",
    "}\n",
    "\n",
    "# Raname columns\n",
    "q323_processed_table_page_1 = raname_page1_columns(\n",
    "    table_df=q323_processed_table_page_1,\n",
    "    column_renames=column_renames,\n",
    "    unnamed_column_start=1\n",
    ")\n",
    "\n",
    "# Process the table\n",
    "q323_processed_df_page_1 = process_and_unpivot_table_p1(q323_processed_table_page_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66b112-c490-4cf7-932e-d14963cab74e",
   "metadata": {},
   "source": [
    "### Q3 2023 - Page 3 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e59009f6-7f29-4425-93d0-96d3416e9eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining conastant list for different phrases\n",
    "canadian_personal_phrases = [ \"Canadian Personal and Business Banking - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Canadian Personal and Business Banking - accounting adjustments (5)\"\n",
    "]\n",
    "\n",
    "capital_markets_phrases = [ \"Capital Markets and Direct Financial Services - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Capital Markets and Direct Financial Services - accounting adjustments (5)\"\n",
    "]\n",
    "\n",
    "canadian_commercial_phrases = [ \"Canadian Commercial Banking and Wealth Management - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Canadian Commercial Banking and Wealth Management - accounting adjustments (5)\"\n",
    "]\n",
    "\n",
    "us_commercial_phrases = [ \"U.S. Commercial Banking and Wealth Management - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"U.S. Commercial Banking and Wealth Management - accounting adjustments (5)\"\n",
    "]\n",
    "\n",
    "corporate_other_phrases = [ \"Corporate and Other - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Corporate and Other - accounting adjustments (5)\"\n",
    "]\n",
    "\n",
    "cibc_total_phrases = [ \"CIBC Total - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"CIBC Total - accounting adjustments (5)\"\n",
    "]\n",
    "\n",
    "commercial_banking_phrases = [ \"Commercial Banking and Wealth Management (US$ millions) - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - accounting adjustments (5)\"\n",
    "]\n",
    "\n",
    "phrases_list_p5 = [canadian_personal_phrases, capital_markets_phrases, canadian_commercial_phrases, us_commercial_phrases, corporate_other_phrases, cibc_total_phrases, commercial_banking_phrases]\n",
    "primary_phrase_list_p5 = [\"Canadian Personal and Business Banking\", \"Capital Markets and Direct Financial Services\", \"Canadian Commercial Banking and Wealth Management\",\n",
    "                      \"U.S. Commercial Banking and Wealth Management\", \"Corporate and Other\", \"CIBC Total\", \"Commercial Banking and Wealth Management (US$ millions)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d599f63-00ee-49e4-96d9-4e9840c48420",
   "metadata": {},
   "outputs": [],
   "source": [
    "q323_processed_df_page_3 = process_table_headers_and_convert(q323_processed_table_page_3, num_header_rows=4)\n",
    "q323_processed_df_page_4 = process_table_headers_and_convert(q323_processed_table_page_4, num_header_rows=4)\n",
    "q323_processed_df_page_5 = process_table_headers_and_convert(q323_processed_table_page_5, num_header_rows=4)\n",
    "q323_processed_df_page_6 = process_table_headers_and_convert(q323_processed_table_page_6, num_header_rows=4)\n",
    "q323_processed_df_page_7 = process_table_headers_and_convert(q323_processed_table_page_7, num_header_rows=4)\n",
    "\n",
    "q323_processed_df_page_3 = melt_table_with_descriptive_text(q323_processed_df_page_3)\n",
    "q323_processed_df_page_4 = melt_table_with_descriptive_text(q323_processed_df_page_4)\n",
    "q323_processed_df_page_5 = melt_table_with_descriptive_text(q323_processed_df_page_5)\n",
    "q323_processed_df_page_6 = melt_table_with_descriptive_text(q323_processed_df_page_6)\n",
    "q323_processed_df_page_7 = melt_table_with_descriptive_text(q323_processed_df_page_7)\n",
    "\n",
    "for phrase, primary_phrase in zip(q3_phrases_list, q3_primary_phrase_list):\n",
    "    q323_processed_df_page_3 = merge_matching_rows(q323_processed_df_page_3, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "for phrase, primary_phrase in zip(phrases_list_p5, primary_phrase_list_p5):\n",
    "    q323_processed_df_page_5 = merge_matching_rows(q323_processed_df_page_5, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "q323_processed_df_page_3['text'] = q323_processed_df_page_3['text'].astype(str) + 'Q3 2023 three months end'\n",
    "q323_processed_df_page_4['text'] = q323_processed_df_page_4['text'].astype(str) + 'Q2 2023 three months end'\n",
    "q323_processed_df_page_5['text'] = q323_processed_df_page_5['text'].astype(str) + 'Q3 2022 three months end'\n",
    "q323_processed_df_page_6['text'] = q323_processed_df_page_6['text'].astype(str) + 'Q3 2023 nine months end'\n",
    "q323_processed_df_page_7['text'] = q323_processed_df_page_7['text'].astype(str) + 'Q3 2022 nine months end'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595fcce2-2881-44ee-9098-86eaf339eaae",
   "metadata": {},
   "source": [
    "### Q3 2023 - Page 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e8b82ae4-3ea6-423c-bf79-755c45e80d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "q323_processed_df_page_8 = process_table_headers_and_dates_for_last_page(q323_processed_table_page_8, num_header_rows=4)\n",
    "\n",
    "date_replacements = {\n",
    "    'nan': np.nan,        # Replace 'nan' with np.nan\n",
    "    '2023 Jul. 31': 'Q3 2023',\n",
    "    '2023 Apr. 30': 'Q2 2023',\n",
    "    '2022 Jul. 31': 'Q3 2022',\n",
    "}\n",
    "\n",
    "q323_processed_df_page_8 = process_and_melt_table_with_date(\n",
    "    table_df=q323_processed_df_page_8,\n",
    "    date_column='Date',\n",
    "    date_replacements=date_replacements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e824b-62cc-4877-9dc0-ac7773bc9dd3",
   "metadata": {},
   "source": [
    "## Q2 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "706966f0-5ae1-40a8-89fb-6a7d8159c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'q223newsrelease-en.pdf'\n",
    "\n",
    "q223_processed_table_page_1 = extract_table_from_pdf(pdf_path, 1, [170, 20, 290, 576])\n",
    "q223_processed_table_page_3 = extract_table_from_pdf(pdf_path, 3, [210, 20, 610, 800])\n",
    "q223_processed_table_page_4 = extract_table_from_pdf(pdf_path, 4)\n",
    "q223_processed_table_page_5 = extract_table_from_pdf(pdf_path, 5)\n",
    "q223_processed_table_page_6 = extract_table_from_pdf(pdf_path, 6)\n",
    "q223_processed_table_page_7 = extract_table_from_pdf(pdf_path, 7)\n",
    "q223_processed_table_page_8 = extract_table_from_pdf(pdf_path, 8,[70, 20, 420, 800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a334e-ad0f-4cfa-bf5c-207a36267c12",
   "metadata": {},
   "source": [
    "### Q2 2023 - Page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bf13cf60-b807-411b-a618-77f94756a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column renames\n",
    "column_renames = {\n",
    "    'Q2/23': 'Q2 2023',\n",
    "    'Q2/22': 'Q2 2022',\n",
    "    'Q1/23': 'Q1 2023',\n",
    "    '1': 'text',\n",
    "    '5': 'YoY Variance',\n",
    "    '6': 'QoQ Variance',\n",
    "}\n",
    "\n",
    "# Raname columns\n",
    "q223_processed_table_page_1 = raname_page1_columns(\n",
    "    table_df=q223_processed_table_page_1,\n",
    "    column_renames=column_renames,\n",
    "    unnamed_column_start=1\n",
    ")\n",
    "\n",
    "# Process the table\n",
    "q223_processed_df_page_1 = process_and_unpivot_table_p1(q223_processed_table_page_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3b4d3-985b-471c-8945-dc1fbdad758e",
   "metadata": {},
   "source": [
    "### Q2 2023 - Page 3 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ec897b7-5a9c-42ac-83d9-ec1a0867b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining conastant list for different phrases\n",
    "canadian_personal_phrases = [\n",
    "    \"Canadian Personal and Business Banking - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Canadian Personal and Business Banking - accounting adjustments and provision for credit losses for\",\n",
    "    \"Canadian Personal and Business Banking - deduction for banks (2)\"\n",
    "]\n",
    "\n",
    "capital_markets_phrases = [\n",
    "    \"Capital Markets and Direct Financial Services - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Capital Markets and Direct Financial Services - accounting adjustments and provision for credit losses for\",\n",
    "    \"Capital Markets and Direct Financial Services - deduction for banks (2)\",\n",
    "]\n",
    "\n",
    "canadian_commercial_phrases = [\n",
    "    \"Canadian Commercial Banking and Wealth Management - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Canadian Commercial Banking and Wealth Management - accounting adjustments and provision for credit losses for\",\n",
    "    \"Canadian Commercial Banking and Wealth Management - performing loans (6)\",\n",
    "]\n",
    "\n",
    "us_commercial_phrases = [\n",
    "    \"U.S. Commercial Banking and Wealth Management - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"U.S. Commercial Banking and Wealth Management - accounting adjustments and provision for credit losses for\",\n",
    "    \"U.S. Commercial Banking and Wealth Management - performing loans (6)\",\n",
    "]\n",
    "\n",
    "corporate_other_phrases = [\n",
    "    \"Corporate and Other - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Corporate and Other - accounting adjustments and provision for credit losses for\",\n",
    "    \"Corporate and Other - performing loans (6)\",\n",
    "]\n",
    "\n",
    "cibc_total_phrases = [\n",
    "    \"CIBC Total - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"CIBC Total - accounting adjustments and provision for credit losses for\",\n",
    "    \"CIBC Total - performing loans (6)\",\n",
    "]\n",
    "\n",
    "commercial_banking_phrases = [\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - accounting adjustments and provision for credit losses for\",\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - performing loans (6)\",\n",
    "]\n",
    "\n",
    "phrases_list_q223 = [canadian_personal_phrases, capital_markets_phrases, canadian_commercial_phrases, us_commercial_phrases, corporate_other_phrases, cibc_total_phrases, commercial_banking_phrases]\n",
    "primary_phrase_list_q223 = [\"Canadian Personal and Business Banking\", \"Capital Markets and Direct Financial Services\", \"Canadian Commercial Banking and Wealth Management\",\n",
    "                      \"U.S. Commercial Banking and Wealth Management\", \"Corporate and Other\", \"CIBC Total\", \"Commercial Banking and Wealth Management (US$ millions)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "60f26ca7-83b8-45c4-b6f3-86a41ec65c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q223_processed_df_page_3 = process_table_headers_and_convert(q223_processed_table_page_3, num_header_rows=4)\n",
    "q223_processed_df_page_4 = process_table_headers_and_convert(q223_processed_table_page_4, num_header_rows=4)\n",
    "q223_processed_df_page_5 = process_table_headers_and_convert(q223_processed_table_page_5, num_header_rows=4)\n",
    "q223_processed_df_page_6 = process_table_headers_and_convert(q223_processed_table_page_6, num_header_rows=4)\n",
    "q223_processed_df_page_7 = process_table_headers_and_convert(q223_processed_table_page_7, num_header_rows=4)\n",
    "\n",
    "q223_processed_df_page_3 = melt_table_with_descriptive_text(q223_processed_df_page_3)\n",
    "q223_processed_df_page_4 = melt_table_with_descriptive_text(q223_processed_df_page_4)\n",
    "q223_processed_df_page_5 = melt_table_with_descriptive_text(q223_processed_df_page_5)\n",
    "q223_processed_df_page_6 = melt_table_with_descriptive_text(q223_processed_df_page_6)\n",
    "q223_processed_df_page_7 = melt_table_with_descriptive_text(q223_processed_df_page_7)\n",
    "\n",
    "for phrase, primary_phrase in zip(phrases_list_q223, primary_phrase_list_q223):\n",
    "    q223_processed_df_page_5 = merge_matching_rows(q223_processed_df_page_5, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "for phrase, primary_phrase in zip(phrases_list_q223, primary_phrase_list_q223):\n",
    "    q223_processed_df_page_7 = merge_matching_rows(q223_processed_df_page_7, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "q223_processed_df_page_3['text'] = q223_processed_df_page_3['text'].astype(str) + 'Q2 2023 three months end'\n",
    "q223_processed_df_page_4['text'] = q223_processed_df_page_4['text'].astype(str) + 'Q1 2023 three months end'\n",
    "q223_processed_df_page_5['text'] = q223_processed_df_page_5['text'].astype(str) + 'Q2 2022 three months end'\n",
    "q223_processed_df_page_6['text'] = q223_processed_df_page_6['text'].astype(str) + 'Q2 2023 six months end'\n",
    "q223_processed_df_page_7['text'] = q223_processed_df_page_7['text'].astype(str) + 'Q2 2022 six months end'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66fedec-5707-4278-9d5c-1640853cc98f",
   "metadata": {},
   "source": [
    "### Q2 2023 - Page 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "46f3c2b9-fde1-4f5a-9c02-8765c20236b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q223_processed_df_page_8 = process_table_headers_and_dates_for_last_page(q223_processed_table_page_8, num_header_rows=4)\n",
    "\n",
    "date_replacements = {\n",
    "    'nan': np.nan,        # Replace 'nan' with np.nan\n",
    "    '2023 Apr. 30': 'Q2 2023',\n",
    "    '2023 Jan. 31': 'Q1 2023',\n",
    "    '2022 Apr. 31': 'Q2 2022',\n",
    "}\n",
    "\n",
    "q223_processed_df_page_8 = process_and_melt_table_with_date(\n",
    "    table_df=q223_processed_df_page_8,\n",
    "    date_column='Date',\n",
    "    date_replacements=date_replacements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa004f-5870-45ed-99b6-2ac138358675",
   "metadata": {},
   "source": [
    "## Q1 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "90cf65b2-956a-4b2f-8d71-791cf6954dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'q123newsrelease-en.pdf'\n",
    "\n",
    "q123_processed_table_page_1 = extract_table_from_pdf(pdf_path, 1, [160, 20, 290, 576])\n",
    "q123_processed_table_page_3 = extract_table_from_pdf(pdf_path, 3, [210, 20, 610, 800])\n",
    "q123_processed_table_page_4 = extract_table_from_pdf(pdf_path, 4)\n",
    "q123_processed_table_page_5 = extract_table_from_pdf(pdf_path, 5, [60, 30, 390, 600])\n",
    "q123_processed_table_page_5_2 = extract_table_from_pdf(pdf_path, 5, [420, 30, 650, 600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66d8e4d-e039-4620-a63d-542b28855e60",
   "metadata": {},
   "source": [
    "### Q1 2023 - Page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5c804ce4-de84-4248-bd6d-df7a17a7cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column renames\n",
    "column_renames = {\n",
    "    'Q1/23': 'Q1 2023',\n",
    "    'Q1/22': 'Q1 2022',\n",
    "    'Q4/22': 'Q4 2022',\n",
    "    '1': 'text',\n",
    "    '5': 'YoY Variance',\n",
    "    '7': 'QoQ Variance',\n",
    "}\n",
    "\n",
    "# Raname columns\n",
    "q123_processed_table_page_1 = raname_page1_columns(\n",
    "    table_df=q123_processed_table_page_1,\n",
    "    column_renames=column_renames,\n",
    "    unnamed_column_start=1\n",
    ")\n",
    "\n",
    "q123_processed_table_page_1.drop(columns='6', inplace = True)\n",
    "\n",
    "# Process the table\n",
    "q123_processed_df_page_1 = process_and_unpivot_table_p1(q123_processed_table_page_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a96f4-cffb-442f-86c0-e94187579585",
   "metadata": {},
   "source": [
    "### Q1 2023 - Page 3 to 5(table 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cfb07b2e-0b27-41d8-b634-6c12ac8d1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining conastant list for different phrases\n",
    "canadian_personal_phrases = [ \"Canadian Personal and Business Banking - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Canadian Personal and Business Banking - accounting adjustments (6)\"\n",
    "]\n",
    "\n",
    "capital_markets_phrases = [ \"Capital Markets and Direct Financial Services - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Capital Markets and Direct Financial Services - accounting adjustments (6)\"\n",
    "]\n",
    "\n",
    "canadian_commercial_phrases = [ \"Canadian Commercial Banking and Wealth Management - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Canadian Commercial Banking and Wealth Management - accounting adjustments (6)\"\n",
    "]\n",
    "\n",
    "us_commercial_phrases = [ \"U.S. Commercial Banking and Wealth Management - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"U.S. Commercial Banking and Wealth Management - accounting adjustments (6)\"\n",
    "]\n",
    "\n",
    "corporate_other_phrases = [ \"Corporate and Other - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Corporate and Other - accounting adjustments (6)\"\n",
    "]\n",
    "\n",
    "cibc_total_phrases = [ \"CIBC Total - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"CIBC Total - accounting adjustments (6)\"\n",
    "]\n",
    "\n",
    "commercial_banking_phrases = [ \"Commercial Banking and Wealth Management (US$ millions) - Acquisition and integration-related costs as well as purchase\",\n",
    "    \"Commercial Banking and Wealth Management (US$ millions) - accounting adjustments (6)\"\n",
    "]\n",
    "\n",
    "phrases_list_p4 = [canadian_personal_phrases, capital_markets_phrases, canadian_commercial_phrases, us_commercial_phrases, corporate_other_phrases, cibc_total_phrases, commercial_banking_phrases]\n",
    "primary_phrase_list_p4 = [\"Canadian Personal and Business Banking\", \"Capital Markets and Direct Financial Services\", \"Canadian Commercial Banking and Wealth Management\",\n",
    "                      \"U.S. Commercial Banking and Wealth Management\", \"Corporate and Other\", \"CIBC Total\", \"Commercial Banking and Wealth Management (US$ millions)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "941345ae-a022-42f9-b6d5-1873aa7ca572",
   "metadata": {},
   "outputs": [],
   "source": [
    "q123_processed_df_page_3 = process_table_headers_and_convert(q123_processed_table_page_3, num_header_rows=4)\n",
    "q123_processed_df_page_4 = process_table_headers_and_convert(q123_processed_table_page_4, num_header_rows=4)\n",
    "q123_processed_df_page_5 = process_table_headers_and_convert(q123_processed_table_page_5, num_header_rows=4)\n",
    "\n",
    "q123_processed_df_page_3 = melt_table_with_descriptive_text(q123_processed_df_page_3)\n",
    "q123_processed_df_page_4 = melt_table_with_descriptive_text(q123_processed_df_page_4)\n",
    "q123_processed_df_page_5 = melt_table_with_descriptive_text(q123_processed_df_page_5)\n",
    "\n",
    "for phrase, primary_phrase in zip(phrases_list_p4, primary_phrase_list_p4):\n",
    "    q123_processed_df_page_4 = merge_matching_rows(q123_processed_df_page_4, phrase, primary_phrase=primary_phrase)\n",
    "\n",
    "q123_processed_df_page_3['text'] = q123_processed_df_page_3['text'].astype(str) + 'Q1 2023 three months end'\n",
    "q124_processed_df_page_4['text'] = q124_processed_df_page_4['text'].astype(str) + 'Q4 2022 three months end'\n",
    "q124_processed_df_page_5['text'] = q124_processed_df_page_5['text'].astype(str) + 'Q1 2022 three months end'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248e561-3963-4f24-b656-7017312de804",
   "metadata": {},
   "source": [
    "### Q1 2023 - Page 5(table 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d0dc057-8e48-4cd7-9815-dfd0a1a1e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "q123_processed_df_page_5_2 = process_table_headers_and_dates_for_last_page(q123_processed_table_page_5_2, num_header_rows=4)\n",
    "\n",
    "date_replacements = {\n",
    "    'nan': np.nan,        # Replace 'nan' with np.nan\n",
    "    '2023 Jan. 30': 'Q1 2023',\n",
    "    '2023 Oct. 31': 'Q4 2023',\n",
    "    '2022 Jan. 31': 'Q1 2022',\n",
    "}\n",
    "\n",
    "q123_processed_df_page_5_2 = process_and_melt_table_with_date(\n",
    "    table_df=q123_processed_df_page_5_2,\n",
    "    date_column='Date',\n",
    "    date_replacements=date_replacements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a19ccd-c141-4a58-b357-8c0d1b5c49b5",
   "metadata": {},
   "source": [
    "# Final Table names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c999460-8ad4-4ed4-9d13-086d1bc99229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data tables\n",
    "q224_processed_df_page_1\n",
    "q224_processed_df_page_2\n",
    "q224_processed_df_page_3\n",
    "q224_processed_df_page_4\n",
    "q224_processed_df_page_5\n",
    "q224_processed_df_page_6\n",
    "q224_processed_df_page_7\n",
    "q224_processed_df_page_8\n",
    "q124_processed_df_page_1\n",
    "q124_processed_df_page_3\n",
    "q124_processed_df_page_4\n",
    "q124_processed_df_page_4_2\n",
    "q124_processed_df_page_5\n",
    "q323_processed_df_page_1\n",
    "q323_processed_df_page_3\n",
    "q323_processed_df_page_4\n",
    "q323_processed_df_page_5\n",
    "q323_processed_df_page_6\n",
    "q323_processed_df_page_7\n",
    "q323_processed_df_page_8\n",
    "q223_processed_df_page_1\n",
    "q223_processed_df_page_3\n",
    "q223_processed_df_page_4\n",
    "q223_processed_df_page_5\n",
    "q223_processed_df_page_6\n",
    "q223_processed_df_page_7\n",
    "q223_processed_df_page_8\n",
    "q123_processed_df_page_1\n",
    "q123_processed_df_page_2\n",
    "q123_processed_df_page_3\n",
    "q123_processed_df_page_4\n",
    "q123_processed_df_page_5\n",
    "q123_processed_df_page_5_2\n",
    "\n",
    "\n",
    "# Test Data\n",
    "q324_processed_df_page_1\n",
    "q324_processed_df_page_3\n",
    "q324_processed_df_page_4\n",
    "q324_processed_df_page_5\n",
    "q324_processed_df_page_6\n",
    "q324_processed_df_page_7\n",
    "q324_processed_df_page_8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
